{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c9be72-30a2-410b-9a56-4f489e318e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def get_headers():\n",
    "    \"\"\"Returns headers from headers.csv file\"\"\"\n",
    "    try:\n",
    "        with open('headers.csv', 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            headers_list = [row[0] for row in reader if row]  # Get first column of each row\n",
    "        \n",
    "        if not headers_list:\n",
    "            print(\"Warning: No headers found in CSV, using default\")\n",
    "            return {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "                'Accept-Language': 'en-US,en;q=0.5',\n",
    "                'Connection': 'keep-alive',\n",
    "            }\n",
    "        \n",
    "        # Pick a random header from the list\n",
    "        selected_header = random.choice(headers_list)\n",
    "        \n",
    "        return {\n",
    "            'User-Agent': selected_header,\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: headers.csv not found, using default header\")\n",
    "        return {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading headers.csv: {e}, using default header\")\n",
    "        return {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0692a7f-f39e-4f33-89d2-5a5e4fa18c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def scrape_article(url: str):\n",
    "    \"\"\"\n",
    "    UNIVERSAL NEWS SCRAPER (Option B)\n",
    "    Extracts headline, image, content, author, publish date\n",
    "    using OG tags, JSON-LD, microdata, fallbacks.\n",
    "    Returns a JSON object (Python dict).\n",
    "    \"\"\"\n",
    "    \n",
    "    headers=get_headers()\n",
    "    \n",
    "    try:\n",
    "        html = requests.get(url, headers=headers, timeout=10).text\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Cannot retrieve URL: {e}\"}\n",
    "    \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Helper functions\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    def get_og(property):\n",
    "        tag = soup.find(\"meta\", property=property)\n",
    "        if tag and tag.get(\"content\"):\n",
    "            return tag[\"content\"].strip()\n",
    "        return None\n",
    "\n",
    "    def get_meta(name):\n",
    "        tag = soup.find(\"meta\", attrs={\"name\": name})\n",
    "        if tag and tag.get(\"content\"):\n",
    "            return tag[\"content\"].strip()\n",
    "        return None\n",
    "\n",
    "    def extract_json_ld():\n",
    "        \"\"\"Extract from JSON-LD schema.org tags.\"\"\"\n",
    "        for script in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "            try:\n",
    "                data = json.loads(script.string, strict=False)\n",
    "                if isinstance(data, dict):\n",
    "                    yield data\n",
    "                elif isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if isinstance(item, dict):\n",
    "                            yield item\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def clean_text(t):\n",
    "        if not t:\n",
    "            return None\n",
    "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "        return t if t else None\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. HEADLINE (OG → JSON-LD → <h1>)\n",
    "    # -----------------------------------------------------\n",
    "    headline = (\n",
    "        get_og(\"og:title\")\n",
    "        or get_meta(\"twitter:title\")\n",
    "    )\n",
    "\n",
    "    # Try JSON-LD headline\n",
    "    if not headline:\n",
    "        for block in extract_json_ld():\n",
    "            if \"headline\" in block:\n",
    "                headline = block[\"headline\"]\n",
    "                break\n",
    "\n",
    "    # Fallback: HTML <h1>\n",
    "    if not headline:\n",
    "        h1 = soup.find(\"h1\")\n",
    "        headline = clean_text(h1.get_text()) if h1 else None\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 2. IMAGE\n",
    "    # -----------------------------------------------------\n",
    "    image = (\n",
    "        get_og(\"og:image\")\n",
    "        or get_meta(\"twitter:image\")\n",
    "    )\n",
    "\n",
    "    # JSON-LD fallback\n",
    "    if not image:\n",
    "        for block in extract_json_ld():\n",
    "            if \"image\" in block:\n",
    "                if isinstance(block[\"image\"], dict) and \"url\" in block[\"image\"]:\n",
    "                    image = block[\"image\"][\"url\"]\n",
    "                elif isinstance(block[\"image\"], str):\n",
    "                    image = block[\"image\"]\n",
    "                break\n",
    "\n",
    "    # HTML fallback\n",
    "    if not image:\n",
    "        img = soup.find(\"img\")\n",
    "        if img and img.get(\"src\"):\n",
    "            image = urljoin(url, img[\"src\"])\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 3. AUTHOR\n",
    "    # -----------------------------------------------------\n",
    "    author = (\n",
    "        get_meta(\"author\")\n",
    "        or get_og(\"article:author\")\n",
    "    )\n",
    "\n",
    "    # JSON-LD author\n",
    "    if not author:\n",
    "        for block in extract_json_ld():\n",
    "            if \"author\" in block:\n",
    "                a = block[\"author\"]\n",
    "                if isinstance(a, dict) and \"name\" in a:\n",
    "                    author = a[\"name\"]\n",
    "                elif isinstance(a, str):\n",
    "                    author = a\n",
    "                break\n",
    "\n",
    "    # Fallback: class contains \"author\"\n",
    "    if not author:\n",
    "        possible = soup.find(class_=re.compile(\"author\", re.I))\n",
    "        if possible:\n",
    "            author = clean_text(possible.get_text())\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 4. PUBLISH DATE\n",
    "    # -----------------------------------------------------\n",
    "    published = (\n",
    "        get_og(\"article:published_time\")\n",
    "        or get_meta(\"date\")\n",
    "    )\n",
    "\n",
    "    # JSON-LD\n",
    "    if not published:\n",
    "        for block in extract_json_ld():\n",
    "            if \"datePublished\" in block:\n",
    "                published = block[\"datePublished\"]\n",
    "                break\n",
    "\n",
    "    # Microdata fallback\n",
    "    if not published:\n",
    "        time_tag = soup.find(\"time\")\n",
    "        if time_tag:\n",
    "            published = time_tag.get(\"datetime\") or time_tag.get_text()\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 5. CONTENT (JSON-LD → <article> → paragraphs)\n",
    "    # -----------------------------------------------------\n",
    "    content = None\n",
    "\n",
    "    # JSON-LD\n",
    "    for block in extract_json_ld():\n",
    "        if \"articleBody\" in block:\n",
    "            content = clean_text(block[\"articleBody\"])\n",
    "            break\n",
    "\n",
    "    # <article> tag fallback\n",
    "    if not content:\n",
    "        article_tag = soup.find(\"article\")\n",
    "        if article_tag:\n",
    "            content = clean_text(article_tag.get_text())\n",
    "\n",
    "    # Paragraph fallback\n",
    "    if not content:\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        content = clean_text(\" \".join([p.get_text() for p in paragraphs]))\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # RETURN JSON OBJECT\n",
    "    # -----------------------------------------------------\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"headline\": headline,\n",
    "        \"image\": image,\n",
    "        \"author\": author,\n",
    "        \"published\": published,\n",
    "        \"content\": content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31676f2-7a55-495d-b5e3-76670c096744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object scrape_article.<locals>.extract_json_ld at 0x1142d8f40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/dd/lh0x43092pq51783xltv1jn00000gn/T/ipykernel_60916/630212016.py\", line 121, in scrape_article\n",
      "RuntimeError: generator ignored GeneratorExit\n",
      "Exception ignored in: <generator object scrape_article.<locals>.extract_json_ld at 0x1142d8f40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/dd/lh0x43092pq51783xltv1jn00000gn/T/ipykernel_60916/630212016.py\", line 159, in scrape_article\n",
      "RuntimeError: generator ignored GeneratorExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"url\": \"https://www.hindustantimes.com/india-news/in-first-rally-since-karur-stampede-vijay-accuses-dmk-of-loot-dynasty-politics-101763882081990.html\",\n",
      "    \"headline\": \"In first rally since Karur stampede, Vijay accuses DMK of \\u2018loot, dynasty politics\\u2019\",\n",
      "    \"image\": \"https://www.hindustantimes.com/ht-img/img/2025/11/23/1600x900/logo/ANI-20250927328-0_1763883151199_1763883162199.jpg\",\n",
      "    \"author\": \"By\",\n",
      "    \"published\": \"2025-11-23T13:14:39+05:30\",\n",
      "    \"content\": \"Tamilaga Vettri Kazhgam (TVK) chief Vijay resumed his campaign for the 2026 Assembly election two months after at least 41 people died in a tragic stampede at his rally in Karur. As actor-turned politician Vijay returned in public sphere for campaign, he took a dig at the ruling DMK, accusing it of loot and dynasty politics\\u201cTVK did not make empty claims like DMK on ending NEET, instead it sought shifting education to state list in Constitution,\\u201d Vijay was quoted as saying by news agency PTI.Vijay slammed the DMK for questioning TVK party over its ideology and asserted that his party was founded on solid ideological standpoints, and it begins with the principle of equality and had, among other things, demanded a caste census, PTI reported.The campaign was held at an indoor auditorium of an educational institution at Sunguvarchattiram in nearby Kanchipuram district where he addressed cadres, admirers and local people.Vijay alleged the DMK's ideology was loot and indirectly attacked it over dynasty politics. The actor-turned politician ridiculed DMK and also accused it of pretension.First rally after Karur stampedeOn September 27, a deadly stampede at Vijay's rally in Tamil Nadu's Karur left 41 people dead. The district administration described the incident as a \\u201cstampede-like crush\\u201d which occurred at Velusamypuram on the Karur\\u2013Erode highway, where thousands had gathered for Vijay\\u2019s \\u2018Velicham Veliyeru\\u2019 ('Let There Be Light') campaign meeting.Chaos broke out when Vijay was addressing the audience after which he had to halt his speech. Eyewitnesses said the trouble began around 7.45 pm when large sections of the crowd, eager to catch a glimpse of Vijay, surged towards the stage barricades. Several people fainted in the suffocating rush with ambulances facing difficulty navigating the jammed ground. Volunteers eventually formed human chains to make way for the rescue operations.Police sources said the Karur rally attracted a crowd far beyond initial estimates. Though permissions were granted for around 30,000 participants, local reports suggested nearly 60,000 people converged. The venue had already been shifted once. Originally planned in central Karur, it was moved after police warned of congestion and traffic risks.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.hindustantimes.com/india-news/in-first-rally-since-karur-stampede-vijay-accuses-dmk-of-loot-dynasty-politics-101763882081990.html\"\n",
    "result = scrape_article(url)\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8804415-6ce9-4bf9-b677-65cd451b72f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
